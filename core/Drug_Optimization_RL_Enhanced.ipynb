{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83e\uddec Enhanced Drug Optimization RL (Discovery2 + EvE Bio)\n\n",
        "**Advanced reinforcement learning for drug discovery with comprehensive analysis**\n\n",
        "## \ud83d\ude80 Features\n",
        "1. **Multi-target analysis** - Compare BTK, EGFR, ALK, and other targets\n",
        "2. **Hyperparameter optimization** - Grid search over learning rates, discount factors\n",
        "3. **Chemical visualization** - RDKit structure rendering and property calculation\n",
        "4. **Portfolio optimization** - Pareto frontier analysis for efficacy-safety-selectivity\n",
        "5. **Persistence** - Save models and results to Google Drive\n",
        "6. **Statistical rigor** - Confidence intervals, hypothesis testing, effect sizes\n",
        "7. **MILES concepts** - MoE routing and distributed training simulation\n\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# @title \ud83d\udce6 Install Enhanced Dependencies\n",
        "!pip -q install --upgrade pip\n",
        "!pip -q install numpy pandas matplotlib seaborn scikit-learn\n",
        "!pip -q install gymnasium==0.29.1 joblib statsmodels lightgbm\n",
        "!pip -q install datasets huggingface_hub\n",
        "!pip -q install rdkit-pypi  # Chemical informatics\n",
        "!pip -q install plotly  # Interactive visualizations\n",
        "!pip -q install optuna  # Hyperparameter optimization\n",
        "!pip -q install scipy  # Statistical tests\n",
        "print('\u2713 All packages installed successfully!')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# @title \ud83d\udcbe Mount Google Drive for Persistence\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import os\n\n",
        "drive.mount('/content/drive')\n\n",
        "# Create project directory in Drive\n",
        "DRIVE_PROJECT_DIR = Path('/content/drive/MyDrive/DrugRL_Project')\n",
        "DRIVE_PROJECT_DIR.mkdir(parents=True, exist_ok=True)\n\n",
        "print(f'\u2713 Project directory: {DRIVE_PROJECT_DIR}')\n",
        "print(f'  All results will be saved here for persistence across sessions')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# @title \ud83d\udd27 Enhanced Setup with Directory Structure\n",
        "import os\n",
        "from pathlib import Path\n",
        "from huggingface_hub import login\n\n",
        "# Local runtime directories\n",
        "BASE_DIR = Path('/content')\n",
        "DATA_DIR = BASE_DIR / 'data'\n",
        "MODELS_DIR = BASE_DIR / 'models'\n",
        "OUT_DIR = BASE_DIR / 'outputs'\n",
        "CACHE_DIR = BASE_DIR / 'cache'\n\n",
        "for d in [DATA_DIR, MODELS_DIR, OUT_DIR, CACHE_DIR]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n\n",
        "# Drive subdirectories for long-term storage\n",
        "DRIVE_RESULTS = DRIVE_PROJECT_DIR / 'results'\n",
        "DRIVE_MODELS = DRIVE_PROJECT_DIR / 'trained_models'\n",
        "DRIVE_FIGURES = DRIVE_PROJECT_DIR / 'figures'\n",
        "DRIVE_CHECKPOINTS = DRIVE_PROJECT_DIR / 'checkpoints'\n\n",
        "for d in [DRIVE_RESULTS, DRIVE_MODELS, DRIVE_FIGURES, DRIVE_CHECKPOINTS]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n\n",
        "print('\u2713 Directory structure created:')\n",
        "print(f'  Local: {OUT_DIR}')\n",
        "print(f'  Drive: {DRIVE_PROJECT_DIR}')\n\n",
        "# HF login\n",
        "hf_token = os.environ.get('HF_TOKEN', '')\n",
        "if hf_token:\n",
        "    login(token=hf_token)\n",
        "    print('\u2713 Logged into Hugging Face')\n",
        "else:\n",
        "    print('\u2139\ufe0f  No HF_TOKEN found (add as Colab Secret if needed)')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# @title \ud83d\udcdd Write Enhanced Environment with Chemical Features\n",
        "%%writefile drug_rl_environment_enhanced.py\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "try:\n",
        "    from rdkit import Chem\n",
        "    from rdkit.Chem import Descriptors, AllChem\n",
        "    RDKIT_AVAILABLE = True\n",
        "except ImportError:\n",
        "    RDKIT_AVAILABLE = False\n",
        "    print('Warning: RDKit not available, chemical features disabled')\n\n",
        "class DrugOptimizationEnvEnhanced(gym.Env):\n",
        "    \"\"\"Enhanced drug optimization environment with chemical features\"\"\"\n",
        "    metadata = {'render_modes': ['human'], 'render_fps': 30}\n\n",
        "    def __init__(self, drug_target_data_path: str, promiscuity_data_path: str,\n",
        "                 cytotox_model_path: str, target_gene: str, max_steps: int = 10,\n",
        "                 efficacy_weight: float = 0.4, safety_weight: float = 0.4,\n",
        "                 selectivity_weight: float = 0.2, use_chemical_features: bool = True):\n",
        "        super().__init__()\n",
        "        self.target_gene = target_gene\n",
        "        self.max_steps = max_steps\n",
        "        self.current_step = 0\n",
        "        self.visited_compounds = set()\n",
        "        self.use_chemical_features = use_chemical_features and RDKIT_AVAILABLE\n",
        "        self.episode_history = []  # Track all episodes\n\n",
        "        # Load data (same as before)\n",
        "        self.drug_target_df = pd.read_csv(drug_target_data_path)\n",
        "        self.drug_target_df = self.drug_target_df[\n",
        "            self.drug_target_df['target__gene'] == target_gene\n",
        "        ]\n",
        "        if self.drug_target_df.empty:\n",
        "            raise ValueError(f'No data for target {target_gene}')\n\n",
        "        self.compounds = self.drug_target_df['compound_id'].unique().tolist()\n",
        "        self.n_compounds = len(self.compounds)\n",
        "        self.compound_to_idx = {c: i for i, c in enumerate(self.compounds)}\n\n",
        "        self.promiscuity_df = pd.read_csv(promiscuity_data_path)\n",
        "        if 'cmpd_id' in self.promiscuity_df.columns:\n",
        "            self.promiscuity_df = self.promiscuity_df.rename(\n",
        "                columns={'cmpd_id': 'compound_id'}\n",
        "            )\n",
        "        self.promiscuity_df = self.promiscuity_df[\n",
        "            self.promiscuity_df['compound_id'].isin(self.compounds)\n",
        "        ]\n",
        "        self.promiscuity_scores = self.promiscuity_df.set_index(\n",
        "            'compound_id'\n",
        "        )['promiscuity_score'].to_dict()\n\n",
        "        self.cytotox_model = joblib.load(cytotox_model_path)\n\n",
        "        # Compute chemical features if SMILES available\n",
        "        self.chemical_features = {}\n",
        "        if self.use_chemical_features and 'compound_smiles' in self.drug_target_df.columns:\n",
        "            self._compute_chemical_features()\n\n",
        "        self.action_space = spaces.Discrete(self.n_compounds)\n",
        "        self.observation_space = spaces.Discrete(1)\n\n",
        "        self.efficacy_weight = efficacy_weight\n",
        "        self.safety_weight = safety_weight\n",
        "        self.selectivity_weight = selectivity_weight\n\n",
        "        self.efficacy_scaler = MinMaxScaler()\n",
        "        self.safety_scaler = MinMaxScaler()\n",
        "        self.selectivity_scaler = MinMaxScaler()\n",
        "        self._precalculate_scaling_bounds()\n\n",
        "    def _compute_chemical_features(self):\n",
        "        \"\"\"Compute RDKit molecular descriptors\"\"\"\n",
        "        for _, row in self.drug_target_df.iterrows():\n",
        "            cid = row['compound_id']\n",
        "            smiles = row.get('compound_smiles', '')\n",
        "            if smiles and cid not in self.chemical_features:\n",
        "                mol = Chem.MolFromSmiles(smiles)\n",
        "                if mol:\n",
        "                    self.chemical_features[cid] = {\n",
        "                        'mw': Descriptors.MolWt(mol),\n",
        "                        'logp': Descriptors.MolLogP(mol),\n",
        "                        'hbd': Descriptors.NumHDonors(mol),\n",
        "                        'hba': Descriptors.NumHAcceptors(mol),\n",
        "                        'tpsa': Descriptors.TPSA(mol),\n",
        "                        'rotatable_bonds': Descriptors.NumRotatableBonds(mol),\n",
        "                        'aromatic_rings': Descriptors.NumAromaticRings(mol)\n",
        "                    }\n\n",
        "    def _precalculate_scaling_bounds(self):\n",
        "        max_act = self.drug_target_df['outcome_max_activity'].max()\n",
        "        min_act = self.drug_target_df['outcome_max_activity'].min()\n",
        "        self.efficacy_scaler.fit(np.array([[min_act], [max_act]]))\n",
        "        self.safety_scaler.fit(np.array([[0.0], [1.0]]))\n",
        "        max_prom = self.promiscuity_df['promiscuity_score'].max()\n",
        "        min_prom = self.promiscuity_df['promiscuity_score'].min()\n",
        "        self.selectivity_scaler.fit(np.array([[min_prom], [max_prom]]))\n\n",
        "    def _get_obs(self):\n",
        "        return 0\n\n",
        "    def _get_info(self, compound_id=None, efficacy=None, safety=None, selectivity=None):\n",
        "        info = {\n",
        "            'current_step': self.current_step,\n",
        "            'max_steps': self.max_steps,\n",
        "            'n_compounds': self.n_compounds,\n",
        "            'visited_compounds_count': len(self.visited_compounds)\n",
        "        }\n",
        "        if compound_id:\n",
        "            info.update({\n",
        "                'compound_id': compound_id,\n",
        "                'efficacy': efficacy,\n",
        "                'safety': safety,\n",
        "                'selectivity': selectivity,\n",
        "                'chemical_features': self.chemical_features.get(compound_id, {})\n",
        "            })\n",
        "        return info\n\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.current_step = 0\n",
        "        self.visited_compounds = set()\n",
        "        self.current_episode_data = []\n",
        "        return self._get_obs(), self._get_info()\n\n",
        "    def step(self, action: int):\n",
        "        self.current_step += 1\n",
        "        compound_id = self.compounds[action]\n\n",
        "        if compound_id in self.visited_compounds:\n",
        "            reward = -10.0\n",
        "            return self._get_obs(), reward, True, False, self._get_info(compound_id)\n\n",
        "        self.visited_compounds.add(compound_id)\n\n",
        "        # Get efficacy\n",
        "        efficacy_data = self.drug_target_df[\n",
        "            self.drug_target_df['compound_id'] == compound_id\n",
        "        ]\n",
        "        efficacy = efficacy_data['outcome_max_activity'].iloc[0] if not efficacy_data.empty else 0.0\n\n",
        "        # Get safety\n",
        "        promiscuity = self.promiscuity_scores.get(compound_id, 0.0)\n",
        "        try:\n",
        "            safety_pred = self.cytotox_model.predict_proba(\n",
        "                np.array([[promiscuity]])\n",
        "            )[:, 1][0]\n",
        "            safety = 1.0 - safety_pred\n",
        "        except:\n",
        "            safety = 0.5\n\n",
        "        # Get selectivity\n",
        "        max_prom = self.promiscuity_df['promiscuity_score'].max()\n",
        "        selectivity = 1.0 - (promiscuity / max_prom) if max_prom > 0 else 0.5\n",
        "        selectivity = max(0.0, selectivity)\n\n",
        "        # Scale and compute reward\n",
        "        scaled_eff = self.efficacy_scaler.transform([[efficacy]])[0][0]\n",
        "        scaled_safe = self.safety_scaler.transform([[safety]])[0][0]\n",
        "        scaled_sel = self.selectivity_scaler.transform([[promiscuity]])[0][0]\n",
        "        scaled_sel = 1.0 - scaled_sel\n\n",
        "        reward = (\n",
        "            self.efficacy_weight * scaled_eff +\n",
        "            self.safety_weight * scaled_safe +\n",
        "            self.selectivity_weight * scaled_sel\n",
        "        )\n\n",
        "        # Store episode data\n",
        "        self.current_episode_data.append({\n",
        "            'step': self.current_step,\n",
        "            'compound_id': compound_id,\n",
        "            'efficacy': efficacy,\n",
        "            'safety': safety,\n",
        "            'selectivity': selectivity,\n",
        "            'reward': reward\n",
        "        })\n\n",
        "        terminated = self.current_step >= self.max_steps\n",
        "        if terminated:\n",
        "            self.episode_history.append(self.current_episode_data.copy())\n\n",
        "        return self._get_obs(), float(reward), terminated, False, self._get_info(\n",
        "            compound_id, efficacy, safety, selectivity\n",
        "        )\n\n",
        "    def render(self, mode='human'):\n",
        "        if mode == 'human':\n",
        "            print(f'Step: {self.current_step}/{self.max_steps}, '\n",
        "                  f'Explored: {len(self.visited_compounds)}')\n\n",
        "    def close(self):\n",
        "        pass\n",
        "\n",
        "print('\u2713 Enhanced environment created')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# @title \ud83d\udce5 Download Discovery2 Data\n",
        "from huggingface_hub import hf_hub_download\n\n",
        "promiscuity_csv = hf_hub_download(\n",
        "    repo_id='pageman/discovery2-results',\n",
        "    repo_type='dataset',\n",
        "    filename='discovery2_promiscuity_scores.csv',\n",
        "    local_dir=str(DATA_DIR),\n",
        "    local_dir_use_symlinks=False\n",
        ")\n\n",
        "cubic_model_path = hf_hub_download(\n",
        "    repo_id='pageman/discovery2-cytotoxicity-models',\n",
        "    filename='cubic_logistic_model.pkl',\n",
        "    local_dir=str(MODELS_DIR),\n",
        "    local_dir_use_symlinks=False\n",
        ")\n\n",
        "print('\u2713 Downloaded Discovery2 artifacts')\n",
        "print(f'  Promiscuity: {promiscuity_csv}')\n",
        "print(f'  Cytotox model: {cubic_model_path}')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# @title \ud83c\udfaf Multi-Target Dataset Loading\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n\n",
        "# Define multiple targets to analyze\n",
        "TARGET_GENES = ['BTK', 'EGFR', 'ALK', 'BRAF']  # Modify as needed\n",
        "LOCAL_CSV = BASE_DIR / 'drug-target-activity.csv'\n\n",
        "def standardize_columns(df):\n",
        "    target_candidates = ['target__gene', 'target_gene', 'target_gene_symbol']\n",
        "    compound_candidates = ['compound_id', 'drug_id', 'compound']\n",
        "    target_col = next((c for c in target_candidates if c in df.columns), None)\n",
        "    compound_col = next((c for c in compound_candidates if c in df.columns), None)\n",
        "    if not target_col or not compound_col:\n",
        "        raise KeyError('Missing required columns')\n",
        "    df = df.rename(columns={target_col: 'target__gene', compound_col: 'compound_id'})\n",
        "    for r in ['outcome_is_active', 'outcome_max_activity']:\n",
        "        if r not in df.columns:\n",
        "            raise KeyError(f'Missing {r}')\n",
        "    return df\n\n",
        "# Load dataset\n",
        "dataset_loaded = False\n",
        "if LOCAL_CSV.exists():\n",
        "    try:\n",
        "        print(f'Loading local CSV: {LOCAL_CSV}')\n",
        "        df = pd.read_csv(LOCAL_CSV, low_memory=False)\n",
        "        df = standardize_columns(df)\n",
        "        print(f'\u2713 Loaded {len(df):,} rows from local CSV')\n",
        "        dataset_loaded = True\n",
        "    except Exception as e:\n",
        "        print(f'\u26a0\ufe0f  Local CSV failed: {e}')\n\n",
        "if not dataset_loaded:\n",
        "    try:\n",
        "        print('Loading EvE Bio dataset from HuggingFace...')\n",
        "        ds = load_dataset('eve-bio/drug-target-activity', split='train')\n",
        "        df = ds.to_pandas()\n",
        "        df = standardize_columns(df)\n",
        "        print(f'\u2713 Loaded {len(df):,} rows from HF')\n",
        "        dataset_loaded = True\n",
        "    except Exception as e:\n",
        "        print(f'\u26a0\ufe0f  HF dataset failed: {e}')\n",
        "        print('Creating synthetic dataset...')\n",
        "        prom = pd.read_csv(promiscuity_csv)\n",
        "        df_list = []\n",
        "        for target in TARGET_GENES:\n",
        "            demo = prom[['compound_id']].sample(n=min(200, len(prom)), random_state=42).copy()\n",
        "            demo['target__gene'] = target\n",
        "            demo['outcome_max_activity'] = (demo['compound_id'].astype('category').cat.codes % 101).astype(float)\n",
        "            demo['outcome_is_active'] = demo['outcome_max_activity'] >= 50.0\n",
        "            df_list.append(demo)\n",
        "        df = pd.concat(df_list, ignore_index=True)\n",
        "        print(f'\u2713 Created synthetic dataset with {len(df):,} rows')\n\n",
        "# Create target-specific CSVs\n",
        "target_csv_paths = {}\n",
        "for target in TARGET_GENES:\n",
        "    df_t = df[df['target__gene'] == target].copy()\n",
        "    if len(df_t) > 0:\n",
        "        csv_path = DATA_DIR / f'drug_target_activity_{target}.csv'\n",
        "        df_t[['compound_id', 'target__gene', 'outcome_is_active', 'outcome_max_activity']].to_csv(\n",
        "            csv_path, index=False\n",
        "        )\n",
        "        target_csv_paths[target] = csv_path\n",
        "        print(f'  {target}: {len(df_t):,} compounds \u2192 {csv_path.name}')\n",
        "    else:\n",
        "        print(f'  {target}: No data found')\n\n",
        "print(f'\\n\u2713 Ready to analyze {len(target_csv_paths)} targets')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# @title \ud83d\udd2c Hyperparameter Sweep with Optuna\n",
        "import optuna\n",
        "from drug_rl_environment_enhanced import DrugOptimizationEnvEnhanced\n",
        "import sys\n",
        "sys.path.insert(0, str(BASE_DIR))\n",
        "from drug_rl_training import QLearningAgent, train_agent, evaluate_agent\n\n",
        "# Choose a target for hyperparameter tuning\n",
        "TUNE_TARGET = list(target_csv_paths.keys())[0]\n",
        "print(f'Tuning hyperparameters for target: {TUNE_TARGET}')\n\n",
        "def objective(trial):\n",
        "    # Sample hyperparameters\n",
        "    lr = trial.suggest_float('learning_rate', 0.01, 0.5, log=True)\n",
        "    gamma = trial.suggest_float('discount_factor', 0.8, 0.99)\n",
        "    epsilon_decay = trial.suggest_float('epsilon_decay', 0.95, 0.999)\n",
        "    \n",
        "    efficacy_weight = trial.suggest_float('efficacy_weight', 0.2, 0.6)\n",
        "    safety_weight = trial.suggest_float('safety_weight', 0.2, 0.6)\n",
        "    selectivity_weight = 1.0 - efficacy_weight - safety_weight\n",
        "    \n",
        "    if selectivity_weight < 0.05:\n",
        "        return -1000  # Invalid\n",
        "    \n",
        "    # Create environment\n",
        "    env = DrugOptimizationEnvEnhanced(\n",
        "        drug_target_data_path=str(target_csv_paths[TUNE_TARGET]),\n",
        "        promiscuity_data_path=str(promiscuity_csv),\n",
        "        cytotox_model_path=str(cubic_model_path),\n",
        "        target_gene=TUNE_TARGET,\n",
        "        max_steps=10,\n",
        "        efficacy_weight=efficacy_weight,\n",
        "        safety_weight=safety_weight,\n",
        "        selectivity_weight=selectivity_weight\n",
        "    )\n",
        "    \n",
        "    # Train agent\n",
        "    agent = QLearningAgent(\n",
        "        n_actions=env.n_compounds,\n",
        "        learning_rate=lr,\n",
        "        discount_factor=gamma,\n",
        "        epsilon_start=1.0,\n",
        "        epsilon_end=0.01,\n",
        "        epsilon_decay=epsilon_decay\n",
        "    )\n",
        "    \n",
        "    train_agent(env, agent, n_episodes=100, max_steps=10, verbose=False)\n",
        "    \n",
        "    # Evaluate\n",
        "    eval_stats = evaluate_agent(env, agent, n_episodes=10)\n",
        "    return eval_stats['avg_reward']\n\n",
        "# Run optimization\n",
        "print('Starting hyperparameter optimization (this may take a few minutes)...')\n",
        "study = optuna.create_study(direction='maximize', study_name='drug_rl_tuning')\n",
        "study.optimize(objective, n_trials=20, show_progress_bar=True)\n\n",
        "print('\\n' + '='*80)\n",
        "print('HYPERPARAMETER OPTIMIZATION RESULTS')\n",
        "print('='*80)\n",
        "print(f'Best value: {study.best_value:.3f}')\n",
        "print(f'Best params: {study.best_params}')\n\n",
        "# Save results\n",
        "trials_df = study.trials_dataframe()\n",
        "trials_df.to_csv(DRIVE_RESULTS / f'optuna_trials_{TUNE_TARGET}.csv', index=False)\n",
        "print(f'\\n\u2713 Saved trials to {DRIVE_RESULTS / f\"optuna_trials_{TUNE_TARGET}.csv\"}')\n\n",
        "# Store best params for later use\n",
        "best_params = study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# @title \ud83c\udfaf Multi-Target Training & Comparison\n",
        "from drug_rl_environment_enhanced import DrugOptimizationEnvEnhanced\n",
        "from drug_rl_training import QLearningAgent, train_agent, evaluate_agent\n",
        "import joblib\n\n",
        "# Train agents for each target\n",
        "multi_target_results = {}\n",
        "trained_agents = {}\n",
        "environments = {}\n\n",
        "for target, csv_path in target_csv_paths.items():\n",
        "    print(f'\\n{\"=\"*80}')\n",
        "    print(f'Training agent for target: {target}')\n",
        "    print(f'{\"=\"*80}')\n",
        "    \n",
        "    # Create environment\n",
        "    env = DrugOptimizationEnvEnhanced(\n",
        "        drug_target_data_path=str(csv_path),\n",
        "        promiscuity_data_path=str(promiscuity_csv),\n",
        "        cytotox_model_path=str(cubic_model_path),\n",
        "        target_gene=target,\n",
        "        max_steps=10,\n",
        "        efficacy_weight=best_params.get('efficacy_weight', 0.4),\n",
        "        safety_weight=best_params.get('safety_weight', 0.4),\n",
        "        selectivity_weight=best_params.get('selectivity_weight', 0.2)\n",
        "    )\n",
        "    environments[target] = env\n",
        "    \n",
        "    # Create agent with best hyperparameters\n",
        "    agent = QLearningAgent(\n",
        "        n_actions=env.n_compounds,\n",
        "        learning_rate=best_params.get('learning_rate', 0.1),\n",
        "        discount_factor=best_params.get('discount_factor', 0.95),\n",
        "        epsilon_start=1.0,\n",
        "        epsilon_end=0.01,\n",
        "        epsilon_decay=best_params.get('epsilon_decay', 0.995)\n",
        "    )\n",
        "    \n",
        "    # Train\n",
        "    training_stats = train_agent(env, agent, n_episodes=200, max_steps=10, verbose=True)\n",
        "    \n",
        "    # Evaluate\n",
        "    eval_stats = evaluate_agent(env, agent, n_episodes=10)\n",
        "    \n",
        "    multi_target_results[target] = {\n",
        "        'rewards': training_stats['rewards'],\n",
        "        'eval_mean': eval_stats['avg_reward'],\n",
        "        'eval_std': eval_stats['std_reward']\n",
        "    }\n",
        "    trained_agents[target] = agent\n",
        "    \n",
        "    # Save agent to Drive\n",
        "    agent_path = DRIVE_MODELS / f'agent_{target}.pkl'\n",
        "    joblib.dump(agent, agent_path)\n",
        "    print(f'\\n\u2713 Saved trained agent to {agent_path}')\n",
        "    \n",
        "    print(f'Evaluation: {eval_stats[\"avg_reward\"]:.3f} \u00b1 {eval_stats[\"std_reward\"]:.3f}')\n\n",
        "print(f'\\n{\"=\"*80}')\n",
        "print('MULTI-TARGET TRAINING COMPLETE')\n",
        "print(f'{\"=\"*80}')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# @title \ud83d\udcca Comprehensive Analysis with Enhanced Tools\n",
        "# Upload enhanced analysis module\n",
        "!wget -q -O drug_rl_enhanced_analysis.py https://raw.githubusercontent.com/YOUR_REPO/drug_rl_enhanced_analysis.py || echo 'Note: Using embedded analysis'\n\n",
        "# For now, embed simplified version\n",
        "from drug_rl_enhanced_analysis import run_comprehensive_analysis\n\n",
        "# Run analysis for each target\n",
        "for target in multi_target_results.keys():\n",
        "    print(f'\\nAnalyzing target: {target}')\n",
        "    output_dir = DRIVE_RESULTS / target\n",
        "    output_dir.mkdir(exist_ok=True)\n",
        "    \n",
        "    analyzer, summary = run_comprehensive_analysis(\n",
        "        training_results={target: multi_target_results[target]},\n",
        "        env=environments[target],\n",
        "        agent=trained_agents[target],\n",
        "        output_dir=output_dir\n",
        "    )\n",
        "    print(f'\u2713 Analysis complete for {target}')\n",
        "    print(f'  Results saved to: {output_dir}')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# @title \ud83e\uddea Chemical Structure Visualization (Top Compounds)\n",
        "try:\n",
        "    from rdkit import Chem\n",
        "    from rdkit.Chem import Draw, Descriptors\n",
        "    import matplotlib.pyplot as plt\n",
        "    from PIL import Image\n",
        "    import io\n",
        "    \n",
        "    # Select a target\n",
        "    VIZ_TARGET = list(trained_agents.keys())[0]\n",
        "    print(f'Visualizing top compounds for: {VIZ_TARGET}')\n",
        "    \n",
        "    # Get top 9 compounds by Q-value\n",
        "    agent = trained_agents[VIZ_TARGET]\n",
        "    env = environments[VIZ_TARGET]\n",
        "    q_values = agent.q_table[0]\n",
        "    top_9_idx = np.argsort(q_values)[-9:][::-1]\n",
        "    \n",
        "    # Check if SMILES data available\n",
        "    df = pd.read_csv(target_csv_paths[VIZ_TARGET])\n",
        "    if 'compound_smiles' not in df.columns:\n",
        "        print('\u26a0\ufe0f  No SMILES data in dataset, skipping visualization')\n",
        "    else:\n",
        "        fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
        "        fig.suptitle(f'Top 9 Compounds for {VIZ_TARGET}', fontsize=16, fontweight='bold')\n",
        "        \n",
        "        for idx, ax in zip(top_9_idx, axes.flatten()):\n",
        "            cmpd_id = env.compounds[idx]\n",
        "            cmpd_data = df[df['compound_id'] == cmpd_id]\n",
        "            \n",
        "            if not cmpd_data.empty and 'compound_smiles' in cmpd_data.columns:\n",
        "                smiles = cmpd_data['compound_smiles'].iloc[0]\n",
        "                mol = Chem.MolFromSmiles(smiles) if smiles else None\n",
        "                \n",
        "                if mol:\n",
        "                    img = Draw.MolToImage(mol, size=(300, 300))\n",
        "                    ax.imshow(img)\n",
        "                    ax.axis('off')\n",
        "                    \n",
        "                    # Add metadata\n",
        "                    mw = Descriptors.MolWt(mol)\n",
        "                    logp = Descriptors.MolLogP(mol)\n",
        "                    q_val = q_values[idx]\n",
        "                    \n",
        "                    ax.set_title(\n",
        "                        f'{cmpd_id[:10]}...\\nQ={q_val:.2f}\\nMW={mw:.1f} LogP={logp:.1f}',\n",
        "                        fontsize=10\n",
        "                    )\n",
        "                else:\n",
        "                    ax.text(0.5, 0.5, 'Invalid\\nSMILES', ha='center', va='center')\n",
        "                    ax.axis('off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        viz_path = DRIVE_FIGURES / f'top_compounds_{VIZ_TARGET}.png'\n",
        "        plt.savefig(viz_path, dpi=300, bbox_inches='tight')\n",
        "        print(f'\u2713 Saved visualization to {viz_path}')\n",
        "        plt.show()\n",
        "        \n",
        "except ImportError:\n",
        "    print('\u26a0\ufe0f  RDKit not available, skipping chemical visualization')\n",
        "except Exception as e:\n",
        "    print(f'\u26a0\ufe0f  Visualization error: {e}')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# @title \ud83d\ude80 MILES/MoE Concepts Demo\n",
        "from miles_concepts_drug_rl import demonstrate_miles_concepts\n",
        "moe, rollout_system = demonstrate_miles_concepts()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# @title \ud83d\udccb Generate Summary Report\n",
        "import json\n",
        "from datetime import datetime\n\n",
        "summary_report = {\n",
        "    'timestamp': datetime.now().isoformat(),\n",
        "    'targets_analyzed': list(multi_target_results.keys()),\n",
        "    'best_hyperparameters': best_params,\n",
        "    'results_by_target': {},\n",
        "    'files_generated': {\n",
        "        'models': [str(p) for p in DRIVE_MODELS.glob('*.pkl')],\n",
        "        'figures': [str(p) for p in DRIVE_FIGURES.glob('*.png')],\n",
        "        'results': [str(p) for p in DRIVE_RESULTS.glob('**/*.csv')]\n",
        "    }\n",
        "}\n\n",
        "for target, results in multi_target_results.items():\n",
        "    summary_report['results_by_target'][target] = {\n",
        "        'final_reward': float(results['rewards'][-1]),\n",
        "        'mean_reward': float(np.mean(results['rewards'])),\n",
        "        'eval_performance': f\"{results['eval_mean']:.3f} \u00b1 {results['eval_std']:.3f}\",\n",
        "        'n_compounds': len(environments[target].compounds)\n",
        "    }\n\n",
        "# Save report\n",
        "report_path = DRIVE_PROJECT_DIR / 'experiment_summary.json'\n",
        "with open(report_path, 'w') as f:\n",
        "    json.dump(summary_report, f, indent=2)\n\n",
        "print('='*80)\n",
        "print('EXPERIMENT SUMMARY')\n",
        "print('='*80)\n",
        "print(json.dumps(summary_report, indent=2))\n",
        "print(f'\\n\u2713 Full report saved to: {report_path}')\n",
        "print(f'\\n\u2705 All results persisted to Google Drive: {DRIVE_PROJECT_DIR}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd27 Troubleshooting\n\n",
        "### Common Issues\n\n",
        "1. **RDKit installation fails**: Restart runtime, or skip chemical visualization\n",
        "2. **EvE dataset access denied**: Add HF_TOKEN as Colab Secret after accepting dataset terms\n",
        "3. **Out of memory**: Reduce n_trials in Optuna or n_episodes in training\n",
        "4. **Drive quota exceeded**: Clear old files in DRIVE_PROJECT_DIR\n\n",
        "### Performance Tips\n\n",
        "- Use GPU runtime for faster hyperparameter tuning (though not required)\n",
        "- Reduce TARGET_GENES list to 2-3 targets to save time\n",
        "- Cache results in Drive and reload instead of retraining\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}